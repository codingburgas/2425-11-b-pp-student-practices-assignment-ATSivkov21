import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))
# üìÇ –ó–∞ —Ä–∞–±–æ—Ç–∞ —Å –ø—ä—Ç–∏—â–∞ –∏ —Ñ–∞–π–ª–æ–≤–∞—Ç–∞ —Å–∏—Å—Ç–µ–º–∞
import os
# üî¢ –ó–∞ —Ä–∞–±–æ—Ç–∞ —Å —á–∏—Å–ª–æ–≤–∏ –º–∞—Å–∏–≤–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª–∞
import numpy as np
# ‚öôÔ∏è –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ—Ç–æ –∏ –¥–æ—Å—Ç—ä–ø –¥–æ –±–∞–∑–∞—Ç–∞
from app import create_app, db
# üìã –ú–æ–¥–µ–ª—ä—Ç –∑–∞ —Å—ä—Ö—Ä–∞–Ω–µ–Ω–∏ –æ—Ç–≥–æ–≤–æ—Ä–∏ –æ—Ç –∞–Ω–∫–µ—Ç–∞—Ç–∞
from app.models import SurveyResponse
# üß† –ò–º–ø–æ—Ä—Ç –Ω–∞ –ª–æ–≥–∏—Å—Ç–∏—á–Ω–∏—è –º–æ–¥–µ–ª –∏ –ø—ä—Ç—è, –∫—ä–¥–µ—Ç–æ —Å–µ –∑–∞–ø–∏—Å–≤–∞
from app.utils.ai_model import model, MODEL_PATH
from sklearn.feature_selection import mutual_info_classif


def get_training_data():
    # –í–∑–∏–º–∞–Ω–µ –Ω–∞ –≤—Å–∏—á–∫–∏ –ø–æ–ø—ä–ª–Ω–µ–Ω–∏ –∞–Ω–∫–µ—Ç–∏ –æ—Ç –±–∞–∑–∞—Ç–∞
    surveys = SurveyResponse.query.all()

    X = []  # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (inputs)
    y = []  # –¶–µ–ª–µ–≤–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç (–∫–ª–∏–∫–Ω–∞—Ç–æ –∏–ª–∏ –Ω–µ)

    for s in surveys:
        # üìè –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ —Ç–µ–∫—Å—Ç–æ–≤–∏ –∏ —á–∏—Å–ª–æ–≤–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        interests_len = len(s.interests or "") / 256
        ad_count = len((s.selected_ads or "").split(',')) / 3
        device_score = 0 if s.device == 'PC' else (1 if s.device == 'Mobile' else 2) / 2
        # –ù–æ–≤–∏ —Å–æ—Ü–∏–∞–ª–Ω–∏ –º–µ–¥–∏–∏
        social_names = (s.social_media_names or "").split(',')
        social_lengths = [float(x) for x in (s.social_media_lengths or "").split(',') if x.strip().replace('.', '', 1).isdigit()]
        num_social = len([n for n in social_names if n.strip()]) / 10  # max 10
        total_social_time = sum(social_lengths) / 24  # max 24h
        X.append([
            s.age / 100,
            s.daily_online_hours / 24,
            device_score,
            interests_len,
            ad_count,
            num_social,
            total_social_time
        ])
        y.append(1 if ad_count > 0 else 0)

    return np.array(X), np.array(y)


def main():
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ Flask –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ—Ç–æ
    app = create_app()

    # –í–ª–∏–∑–∞–Ω–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ—Ç–æ –∑–∞ –¥–æ—Å—Ç—ä–ø –¥–æ –±–∞–∑–∞—Ç–∞
    with app.app_context():
        # –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –æ—Ç –±–∞–∑–∞—Ç–∞
        X, y = get_training_data()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ –∏–º–∞ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ –¥–∞–Ω–Ω–∏ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ
        if len(X) == 0:
            print("No survey data found. Please collect data first.")
            return

        using_fake = False
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ –∏–º–∞ –ø–æ–Ω–µ –¥–≤–∞ –∫–ª–∞—Å–∞ –≤ —Ü–µ–ª–µ–≤–∏—è –≤–µ–∫—Ç–æ—Ä
        if len(set(y)) < 2:
            print("Warning: Not enough class diversity in real data. Using a small fake dataset for training.")
            # Generate a small fake dataset with both classes
            X = np.array([
                [0.18, 0.2, 0.5, 0.3, 0.33, 0.3, 0.2],  # class 0
                [0.25, 0.4, 0.0, 0.5, 0.66, 0.6, 0.4],  # class 1
                [0.30, 0.1, 1.0, 0.1, 0.0, 0.1, 0.1],   # class 0
                [0.40, 0.8, 0.5, 0.8, 1.0, 0.8, 0.7]    # class 1
            ])
            y = np.array([0, 1, 0, 1])
            using_fake = True

        # –†–∞–∑–¥–µ–ª—è–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–≤–∞–Ω–µ (80/20), –æ—Å–≤–µ–Ω –∞–∫–æ –µ —Ñ–∞–ª—à–∏–≤ —Å–µ—Ç
        if using_fake:
            X_train, X_test = X, X
            y_train, y_test = y, y
            print("Warning: Using all fake data for both training and evaluation. Metrics are not meaningful.")
        else:
            split_idx = int(0.8 * len(X))
            X_train, X_test = X[:split_idx], X[split_idx:]
            y_train, y_test = y[:split_idx], y[split_idx:]

        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –º–æ–¥–µ–ª–∞ —Å —Ä–µ–∞–ª–Ω–∏—Ç–µ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—Å–∫–∏ –¥–∞–Ω–Ω–∏
        model.fit(X_train, y_train)

        # –û—Ü–µ–Ω—è–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞
        metrics = model.evaluate(X_test, y_test)
        
        # –ó–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª–∞ –≤—ä–≤ —Ñ–∞–π–ª (model.pkl)
        model.save()
        
        print(f"Model trained and saved to {MODEL_PATH}")
        print("\nModel Performance Metrics:")
        for k, v in metrics.items():
            print(f"{k}: {v}")
        
        # –ó–∞–ø–∞–∑–≤–∞–Ω–µ –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏—Ç–µ –≤ –æ—Ç–¥–µ–ª–µ–Ω —Ñ–∞–π–ª
        import json
        metrics_file = 'instance/model_metrics.json'
        with open(metrics_file, 'w') as f:
            json.dump(metrics, f, indent=2)
        print(f"Metrics saved to {metrics_file}")

        # Information gain (mutual information)
        feature_names = [
            'age', 'daily_online_hours', 'device', 'interests_len', 'ad_count', 'num_social', 'total_social_time'
        ]
        info_gain = mutual_info_classif(X_train, y_train, discrete_features=False)
        metrics['information_gain'] = dict(zip(feature_names, info_gain.tolist()))


if __name__ == "__main__":
    main() 